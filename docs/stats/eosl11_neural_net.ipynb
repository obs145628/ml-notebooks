{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection Pursuit Regression\n",
    "\n",
    "The PPR model has the form:\n",
    "\n",
    "$$f(x) = \\sum_{m=1}^M g_m(w_m^Tx)$$\n",
    "\n",
    "with $g_m: \\mathbb{R} \\to \\mathbb{R}$ unspecified functions, $w_m$ and $x \\in \\mathbb{R}^p$.  \n",
    "\n",
    "For $M$ large enough, and special kinds of $g_m$, the model can approximate any continuous functions, it's called a universal approximator.  \n",
    "\n",
    "We fit the model by finding the $g_m$ and $w_m$ that minimizes the following criterion:\n",
    "$$\\sum_{i=1}^N \\left( y_i - \\sum_{m-1}^M g_m(w_m^Tx_i) \\right) ^2$$  \n",
    "\n",
    "If the $g_m$ are fixed, we can solve it one $g$ at a time, using a quasi-newton method:\n",
    "\n",
    "$$\\sum_{i=1}^N (y_i - g(w^Tx_i))^2 \\approx \\sum_{i=1}^N g'(w^T_\\text{old}x_i)^2 \\left( (w_\\text{old}^Tx_i + \\frac{y_i - g(w^T_{old}x_i)}{g'(w^T_\\text{old}x_i)}) - w^T x_i \\right)^2$$\n",
    "\n",
    "We can minimize the right-hand side using a weighted least squares to find $w$, the new weights estimates.  \n",
    "After several iterations, $w$ converges to the weights that minimizes the criterion.  \n",
    "We can then go to the next $g$ and fit $w$ with the residual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPR Algorithm:\n",
    "\n",
    "1. Set $f_0(x) = 0$\n",
    "2. For $m=1$ to $M$:\n",
    "\n",
    "    - Initialize $w_m$ randomly\n",
    "    - Let the residual $r_i = y_i - f_{m-1}(x_i)$\n",
    "    - Let the target $\\hat{y}_i = w^T_\\text{old}x_i \\frac{y_i - g(w^T_\\text{old} x_i)}{g'(w^T_\\text{old} x_i)}$\n",
    "    - Let the weights $v_i = g'(w^T_\\text{old} x_i)^2$\n",
    "    - Solve the WLS of $x_i$ onto $\\hat{y}_i$ with weights $v_i$ iteratively until convergence\n",
    "    - Set $f_m(x) = f_{m-1}(x) + g_m(w_m^Tx)$\n",
    "\n",
    "3. Output $f(x) = f_M(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "We focused on vanilla net, with only one hidden layer. The network has $p$ inputs, $K$ outputs, and the hidden layer size is $M$.  \n",
    "$$Z_m = \\sigma (\\alpha_{0m} + \\alpha^T_m x), \\space m=1,\\text{...},M$$\n",
    "$$T_k = \\beta_{0k} + \\beta^T_Z x), \\space k=1,\\text{...},K$$\n",
    "$$f_k(X) = g_k(T), \\space k=1,\\text{...},K$$  \n",
    "\n",
    "Usually, the activation function $\\sigma$ is the sigmoid: $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$\n",
    "\n",
    "$g_k$ is a final transformation of output vectors. For regression, it's usually the identity. For classification, it's usually the softmax function:\n",
    "$$g_k(T) = \\frac{e^{T_k}}{\\sum_{l=1}^K e^{T_l}}$$\n",
    "\n",
    "We can think of $Z_m$ as the basis expansion (non-linear) of the original inputs $X$. The network is then a simple linear or logistic model with this transformation as input.  \n",
    "\n",
    "If $\\sigma$ is a linear function, the model reduces to a simple linear or logistic model. A non-linear $\\sigma$ greaty enlarges the class of linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Neural Networks\n",
    "\n",
    "We define $\\theta$ as the whole set of weights of our network, containing $\\alpha_{0m}, \\alpha_m, \\beta_{0k}, \\beta_k$, so $M(p+1) + K(M + 1)$ weights.  \n",
    "\n",
    "For regression we usually use the sum-of-squared errors:\n",
    "$$R(\\theta) = \\sum_{k=1}^K\\sum_{i=1}^N (y_{ik} - f_k(x_i))^2$$\n",
    "\n",
    "For $K$-classes classification we usually use the cross-entropy (deviance):\n",
    "\n",
    "$$R(\\theta) = -\\sum_{k=1}^K\\sum_{i=1}^N y_{ik} \\log f_k(x_i)$$\n",
    "\n",
    "\n",
    "The model is fit using gradient descent. Backprogation makes use of the chain rule to compute the gradients of every weights:\n",
    "\n",
    "For sum of squares, let's define:\n",
    "$$R(\\theta) = \\sum_{i=1}^N R_i$$\n",
    "$$\\text{with } R_i = \\sum_{k=1}^K (y_{ik} - f_k(x_i))^2$$\n",
    "\n",
    "$$\\frac{\\partial R_i}{\\partial \\beta_{km}} = -2(y_{ik} - f_k(x_i)) g'_k(\\beta^T_kz_i) z_{mi}$$\n",
    "$$\\frac{\\partial R_i}{\\partial \\alpha_{ml}} = -2(y_{ik} - f_k(x_i)) g'_k(\\beta^T_kz_i) \\beta_{km} \\sigma'(\\alpha_m^Tx_i) x_{il}$$\n",
    "\n",
    "A gradient descent update has the form:\n",
    "$$\\beta_{km} \\leftarrow \\beta_{km} - \\gamma \\sum_{i=1}^N \\frac{\\partial R_i}{\\partial \\beta_{km}}$$\n",
    "$$\\alpha_{ml} \\leftarrow \\alpha_{ml} - \\gamma \\sum_{i=1}^N \\frac{\\partial R_i}{\\partial \\alpha_{ml}}$$\n",
    "\n",
    "with $\\gamma$ the learning rate.  \n",
    "\n",
    "The backprogagation is a 2-pass algorithm: A forward pass that computes the output from the input, and the backward pass, that goes backward to compute the weights gradients.  \n",
    "\n",
    "These updates are in batch learning, getting all datasets at once. But it can also be done with a few or only one example between each update.  \n",
    "An epoch is a sweep through the entiere training set.  \n",
    "Usuaully, the learning rate $\\gamma$ should decrease over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 68.14316071888997\n",
      "Epoch 11: loss = 31.283955204056245\n",
      "Epoch 21: loss = 29.373307553038913\n",
      "Epoch 31: loss = 31.003852829779998\n",
      "Epoch 41: loss = 26.69283436805687\n",
      "Epoch 51: loss = 25.902082837579204\n",
      "Epoch 61: loss = 25.55904596360541\n",
      "Epoch 71: loss = 25.7156240681505\n",
      "Epoch 81: loss = 24.62320562334049\n",
      "Epoch 91: loss = 26.556330393202682\n",
      "Epoch 101: loss = 25.510289678671853\n",
      "Epoch 111: loss = 24.68394423811551\n",
      "Epoch 121: loss = 25.51523731746356\n",
      "Epoch 131: loss = 25.82871033408864\n",
      "Epoch 141: loss = 25.77346142519554\n",
      "Epoch 151: loss = 26.84860736802371\n",
      "Epoch 161: loss = 26.748085227790654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiw/rep/ml-notebooks/env/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171: loss = 25.98840721012171\n",
      "Epoch 181: loss = 26.203457693819388\n",
      "Epoch 191: loss = 28.633488567920423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "class VanillaNetReg:\n",
    "    \n",
    "    def __init__(self, ninputs, nhidden, noutputs):\n",
    "        self.p = ninputs\n",
    "        self.M = nhidden\n",
    "        self.K = noutputs\n",
    "        \n",
    "        self.w0 = np.random.randn(ninputs, nhidden)\n",
    "        self.b0 = np.random.randn(nhidden)\n",
    "        self.w1 = np.random.randn(nhidden, noutputs)\n",
    "        self.b1 = np.random.randn(noutputs)\n",
    "    \n",
    "    def fit(self, X, y, nepochs, batch_size, lr):\n",
    "        \n",
    "        for epoch in range(nepochs):\n",
    "            \n",
    "            p = np.random.permutation(len(X))\n",
    "            X, y = X[p], y[p]\n",
    "            for ki in range(0, len(X_train), batch_size):\n",
    "                Xb = X[ki:ki+batch_size]\n",
    "                yb = y[ki:ki+batch_size]\n",
    "                self.backprop(Xb, yb, lr)\n",
    "               \n",
    "            if epoch % 10 == 0:\n",
    "                print('Epoch {}: loss = {}'.format(epoch + 1,\n",
    "                                                  self.loss(X, y)/len(X)))\n",
    "        \n",
    "    \n",
    "    def backprop(self, X, y, lr):\n",
    "        z0 = X @ self.w0 + self.b0\n",
    "        y0 = sigmoid(z0)\n",
    "        z1 = y0 @ self.w1 + self.b1\n",
    "        y1 = z1\n",
    "        \n",
    "        dy1 = 2 * (y1 - y)\n",
    "        dz1 = dy1\n",
    "        dw1 = y0.T @ dz1\n",
    "        db1 = np.sum(dz1, axis=0)\n",
    "        dy0 = dz1 @ self.w1.T\n",
    "        dz0 = z0 * sigmoid_prime(dy0)\n",
    "        dw0 = X.T @ dz0\n",
    "        db0 = np.sum(dz0, axis=0)\n",
    "        dx = dz0 @ self.w0.T\n",
    "\n",
    "        self.w0 -= lr * dw0\n",
    "        self.b0 -= lr * db0\n",
    "        self.w1 -= lr * dw1\n",
    "        self.b1 -= lr * db1\n",
    "        \n",
    "    def forward(self, X):\n",
    "        z0 = X @ self.w0 + self.b0\n",
    "        y0 = sigmoid(z0)\n",
    "        z1 = y0 @ self.w1 + self.b1\n",
    "        y1 = z1\n",
    "        return y1\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        preds = self.forward(X)\n",
    "        return np.sum((y - preds)**2)\n",
    "        \n",
    "\n",
    "X, y = load_boston().data, load_boston().target\n",
    "X = X.astype(np.float32)\n",
    "X = X / np.std(X, axis=0)\n",
    "y = y.reshape(-1, 1).astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=15)\n",
    "\n",
    "\n",
    "model = VanillaNetReg(ninputs=X.shape[1], nhidden=40, noutputs=1)\n",
    "model.fit(X_train, y_train, nepochs=200, batch_size=32, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Issues in training neural nets\n",
    "\n",
    "## Starting values\n",
    "\n",
    "If weights are near $0$, the sigmoid is roughly linear, and the model is roughly linear.  \n",
    "Exact $0$ leads to $0$ derivative and the network doesn't learn.  \n",
    "To high weights leads to poor solutions.  \n",
    "Usually, it's better to start with near $0$ weights.\n",
    "\n",
    "## Overfitting\n",
    "\n",
    "Neural networks often overfit because they have too many weights.  \n",
    "Early stopping is a technique to reduce overfitting. Whe stop training before reaching a minimum, when the error on a validation set starts increasing.  \n",
    "\n",
    "Another solution is weight decay, we add a penatly $\\lambda J(\\theta)$ to $R(\\theta)$:\n",
    "$$J(\\theta) = \\sum_{k,m} \\beta_{km}^2 + \\sum_{m,l} \\alpha_{ml}^2$$\n",
    "with $\\lambda \\geq 0$ hyperparameter. It shrink the weights towards $0$.  \n",
    "\n",
    "Another penaltty is weight elimination, that shrink smaller weights more:\n",
    "$$J(\\theta) = \\sum_{k,m} \\frac{\\beta_{km}^2}{1 + \\beta_{km}^2} + \\sum_{m,l} \\frac{\\alpha_{ml}^2}{1+\\alpha_{ml}^2}$$\n",
    "\n",
    "## Scaling of the inputs\n",
    "\n",
    "The scaling of the inputs also determines the effective scaling of the weights. It's best to standardize all inputs to mean $0$ and standard deviation $1$.\n",
    "\n",
    "## Number of hidden units and layers\n",
    "\n",
    "It's better to have too many hidden units than too few. With too few, the model might not be complex enought to learn the correct representation.  \n",
    "With too many, extra weights can be shrunk towards $0$ with the proper regularization.  \n",
    "\n",
    "The number of layers is chosen by background knowledge and experimentation. Multple hidden layers allows construction of hierarchical features.\n",
    "\n",
    "## Multiple Minima\n",
    "\n",
    "$R(\\theta)$ as many local minima, and the final solution is quite dependant of the starting weights.  \n",
    "One can try several starting configurations and choose the one with the lowest error, or average over several networks, or use another approach such as bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Net\n",
    "\n",
    "[Bayesian Methods for Neural Networks](https://www.microsoft.com/en-us/research/wp-content/uploads/1995/01/NCRG_95_009.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let consider a feedforward neural network that maps an input vector $x \\in \\mathbb{R}^p$ to an output value $y \\in \\mathbb{R}$, using a weights vector $w \\in \\mathbb{R}^W$.  \n",
    "The observed dataset $D$ consist of $N$ input vector $x_i$ and corresponding target $t_i$.\n",
    "\n",
    "## Prediction\n",
    "\n",
    "We can find the posterior distribution of the weights using Bayes theorem:\n",
    "$$p(w|D) = \\frac{p(D|w)p(w)}{p(D)}$$\n",
    "\n",
    "The conditional distribution $p(D|w)$ is called the likelihood. The conventional approach is to find $w^*$ maximizing the likelihood function.  \n",
    "$p(w)$ is a prior distribution over the weights.  \n",
    "\n",
    "In order to evaluate the posterior $p(w|D)$, we need expressions for both the prior distribution $p(w)$ and the likelihood function $p(D|w)$.  \n",
    "\n",
    "One simple choice or a prior is a multivariate normal distribution with mean $\\vec{0}$ and fixed variance $\\alpha^{-1}$:\n",
    "\n",
    "$$p(w) = \\frac{1}{Z_W(\\alpha)} \\exp (-\\frac{\\alpha}{2}||w||^2)$$\n",
    "$$\\text{with } Z_W(\\alpha) = \\left( \\frac{2 \\pi}{\\alpha} \\right) ^{W/2}$$  \n",
    "\n",
    "For the likelihhod function, let's suppose our model follows a Gaussian distribution, with mean the output of the network, and fixed variance $\\beta^{-1}$:\n",
    "$$p(t|x,w) = \\left( \\frac{\\beta}{2 \\pi} \\right) ^{1/2} \\exp \\left( \\frac{\\beta}{2} (y(x;w) - t)^2 \\right)$$\n",
    "\n",
    "\n",
    "The likelihood function is then:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(D|w)  & = \\prod_{n=1}^N p(t^n|x^n,w) \\\\\n",
    "& = \\frac{1}{Z_D(\\beta)} \\exp \\left( -\\frac{\\beta}{2} \\sum_{i=1}^N (y(x_i;w) - t_i)^2 \\right)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\\text{with } Z_D(\\beta) = \\left( \\frac{2\\pi}{\\beta} \\right) ^{N/2}$$\n",
    "\n",
    "$\\alpha$ and $\\beta$ are hyperpameters, let's suppose for now that they are know, fixed values.  \n",
    "\n",
    "We can make prediction for a new $x$ by integrating over the weights:\n",
    "$$p(t|x,D) = \\int p(t|x,w)p(w|D)dw$$\n",
    "\n",
    "If the posterior $p(w|D)$ is sharply peaked around $w_{MP}$ (center, maximum value of the distribution), then we can approximate is using:\n",
    "\n",
    "$$p(t|x,D) \\approx p(t|x,w_{MP})$$\n",
    "\n",
    "Predictions are made using the neural network, with weights $w_{MP}$. We need to find the $w$ that maximizes the posterior $p(w|D)$.  \n",
    "Instead of maximizing the posterior probability, let's minimize the negative logarithm of the posterior probability. For this particular prior distribution and likelihood function, we have to minize the following criterion:\n",
    "$$E(w) = \\frac{\\beta}{2} \\sum_{i=1}^N (y(x_i:w) - t_i))^2 + \\frac{\\alpha}{2} ||w||^2$$  \n",
    "Up to a constant factor, this is the same as minimizing the usual sum-of-squares error with $L2$ regularization.  \n",
    "\n",
    "## Confidence interval\n",
    "\n",
    "We can use the Bayesian Neural Network to get a confidence interval around the predictions. We can make a Gaussian approximation of the posterior $p(w|D)$.    \n",
    "Let's estimate $E(w)$ using a second-order taylor expansion:\n",
    "$$E(w) = E(w_{MP}) + \\frac{1}{2} (w - w_{MP})^T A (w - w_{MP})$$\n",
    "\n",
    "$A$ is the hessian matrix of $E$ with respect to the weigthts, calculated at $w=w_{MP}$.  \n",
    "\n",
    "Let's approximate the network $y(x;w)$ by a linar expansion:\n",
    "$$y(x;w) = y(x;w_{MP}) + g^T\\Delta w$$\n",
    "with $\\Delta w = w - w_{MP}$ and $g = \\nabla_w y(x; w_{MP})$  \n",
    "\n",
    "With these approximations, the prediction becames Gaussian and can be evaluated:\n",
    "$$p(t|x,D) = \\frac{1}{(2 \\pi \\sigma_t^2)^{1/2}} \\exp \\left( - \\frac{(t - y_{MP})^2}{2 \\sigma_t^2} \\right)$$\n",
    "\n",
    "The distribution has mean $y_{MP} = y(x;w_{MP})$ and variance $\\sigma_t^2$ given by:\n",
    "$$\\sigma_t^2 = \\frac{1}{\\beta} + g^TA^{-1}g$$\n",
    "\n",
    "We can use this distribution to estimate confidence intervals of new predictions.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "We need to chose the correct values for $\\alpha$ and $\\beta$.  \n",
    "The posterior is given by:\n",
    "$$p(w|D) = \\int \\int p(w|\\alpha,\\beta,D)p(\\alpha,\\beta|D)d\\alpha d\\beta$$\n",
    "\n",
    "Let's suppose the posterior $p(\\alpha,\\beta|D)$ is sharply peaked around their maximum $\\alpha_{MP}$ and $\\beta_{MP}$. Then:\n",
    "$$p(w|D) \\approx p(w|\\alpha_{MP}, \\beta_{MP},D)$$\n",
    "\n",
    "We need to find the hyperparemets values that maximize the probability of the posterior $p(\\alpha, \\beta|D)$:\n",
    "\n",
    "$$p(\\alpha, \\beta|D) = \\frac{p(D|\\alpha, \\beta) p(\\alpha,\\beta)}{p(D)}$$\n",
    "\n",
    "We need to choose a prior $p(\\alpha,\\beta)$. Such a prior on hyperparameters is called a hyperprior.  \n",
    "We chose an non-informative prior, because whe have no idea of what values they could be. It gives equal weights to all possible values.  \n",
    "The maximum posterior value is found my maximizing the likelihood term, $p(D|\\alpha,\\beta)$, also called the evidence. It can be rewritten as:\n",
    "$$p(D|\\alpha,\\beta) = \\int p(D|w,\\beta) p(w|\\alpha)dw$$\n",
    "\n",
    "It simplifies to:\n",
    "$$p(D|\\alpha,\\beta) = \\frac{1}{Z_D(\\beta)} \\frac{1}{Z_W(\\alpha)} \\int \\exp (-E(w)) dw$$\n",
    "\n",
    "Using the taylor expension over $E(w)$ as above, this distribution becames tractable, and the resulting expression can be maximized with respect to $\\alpha$ and $\\beta$.  \n",
    "We finally get expressions for $\\alpha_{MP}$ and $\\beta_{MP}$ that can be used in the rest of the calculations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
