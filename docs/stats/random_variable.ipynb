{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete random variable\n",
    "\n",
    "$X$ discrete, can only take an enumerable number values.  \n",
    "\n",
    "## Probability Mass Function (PMF)\n",
    "\n",
    "$$p(a) = P\\{X = a\\}$$\n",
    "$$\\forall i: \\space p(x_i) \\geq 0$$\n",
    "$$\\sum_{i=1}^\\infty p(x_i) = 1$$\n",
    "\n",
    "\n",
    "## Cumlative Distribution Fuction (CDF)\n",
    "\n",
    "$$F(a) = P\\{X \\leq a\\} = \\sum_{x_i \\leq a} p(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous Random Variable\n",
    "\n",
    "$X$ conitnous variable, can take an infinite number of real values.\n",
    "\n",
    "## Probability Density Function (PDF):\n",
    "\n",
    "$$P\\{X \\in B\\} = \\int_{B} f(x)dx$$\n",
    "$$P{a \\leq X \\leq a} = \\int_a^b f(x)dx$$\n",
    "$$P \\{ X \\in ]-\\infty; +\\infty[ \\} = 1$$\n",
    "$$P \\{ X = a \\} = 0$$\n",
    "\n",
    "## Cumulative Distribution Function (CDF)\n",
    "\n",
    "$$F(a) = P \\{X < a \\} = P \\{ X \\leq a \\} = \\int_{-\\infty}^a f(x)dx$$\n",
    "$$\\frac{d}{da} F(a) = f(a)$$\n",
    "$$P \\{a \\leq X \\leq b \\} = F(b) - F(a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint distributions\n",
    "\n",
    "## Discrete joint distributions\n",
    "\n",
    "$$p(x,y) = P \\{X=x, Y=y\\}$$\n",
    "$$p_X(x) = \\sum_y p(x,y)$$\n",
    "$$p_Y(y) = \\sum_x p(x,y)$$\n",
    "\n",
    "## Continuous joint distributions\n",
    "\n",
    "$$P \\{X \\in A, Y \\in B\\} = \\int_B \\int_A f(x,y)dxdy$$\n",
    "$$f(a, b) = \\frac{\\partial^2}{\\partial a \\partial b} F(a,b)$$\n",
    "$$P \\{X \\in A\\} = \\int_A \\int_{-\\infty}^{+\\infty} f(x,y)dydx$$\n",
    "$$P \\{Y \\in B\\} = \\int_B \\int_{-\\infty}^{+\\infty} f(x,y)dxdy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional distributions\n",
    "\n",
    "$$P_{X|Y}(x|y) = P\\{X = x | Y=y\\} = \\frac{p(x,y)}{p_Y(y)} \\text{ (discrete variables)}$$\n",
    "$$f_{X|Y}(x|y) = P\\{X = x | Y=y\\} = \\frac{f(x,y)}{f_Y(y)} \\text{ (continuous variables)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependance\n",
    "\n",
    "Two random variables are independant if the value of one does not affect the probability distribution of the other.  \n",
    "\n",
    "Thwo discrete random variables $X$ and $Y$ are independant if and only if:\n",
    "$$p_{X,Y}(x,y) = p_X(x)p_Y(y) \\space \\forall x,y$$\n",
    "\n",
    "Thwo continuous random variables $X$ and $Y$ are independant if and only if:\n",
    "$$F_{X,Y}(x,y) = F_X(x)F_Y(y) \\space \\forall x,y$$\n",
    "\n",
    "The same condition holds with the probability density $f$.  \n",
    "\n",
    "If two random variables are not indepandant, they are called depandant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation\n",
    "\n",
    "The expection of a random variable is the average value of this random variable.\n",
    "\n",
    "$$\\mathbb{E}[X] = \\sum_{i=1}^n x_ip(x_i) \\text{  (discrete variable)}$$\n",
    "$$\\mathbb{E}[X] = \\int_{-\\infty}^{+\\infty} xf(x)dx \\text{  (continous variable)}$$\n",
    "\n",
    "The expecation of an expression $\\mathbb{E}_{x \\sim X}[g(x)]$ is the average value of $f$, when $x$ comes from the random variable $X$.\n",
    "\n",
    "$$\\mathbb{E}[g(X)] = \\sum_{i=1}^n g(x_i)p(x_i) \\text{  (discrete variable)}$$\n",
    "$$\\mathbb{E}[g(X)] = \\int_{-\\infty}^{+\\infty} g(x)f(x)dx \\text{  (continous variable)}$$\n",
    "\n",
    "## Properties\n",
    "\n",
    "$$\\mathbb{E}[X+Y] = \\mathbb{E}[X] + \\mathbb{E}[Y]$$\n",
    "$$\\mathbb{E}[\\alpha X] = \\alpha \\mathbb{E}[X], \\space \\alpha \\in \\mathbb{R}$$\n",
    "\n",
    "## Estimate\n",
    "\n",
    "Let $x \\in \\mathbb{R}^N$ a sample of size $N$ from random variable $X$.  An estimate of the expectation (or mean) of $X$ is:\n",
    "$$\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1737433992156947\n",
      "3.173743399215695\n"
     ]
    }
   ],
   "source": [
    "def mean(x):\n",
    "    N = len(x)\n",
    "    res = 0\n",
    "    for i in range(N):\n",
    "        res += x[i]\n",
    "    return res / N\n",
    "\n",
    "x = np.random.randn(137) * 1.5 + 3.1\n",
    "print(mean(x))\n",
    "print(np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance\n",
    "\n",
    "The variance is a mesure of how much the value of a random variable change from it's expected value.\n",
    "\n",
    "$$\\text{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$$\n",
    "\n",
    "$$\\text{Var}(\\alpha X + \\beta) = \\alpha^2 \\text{Var}(X), \\space \\alpha, \\beta \\in \\mathbb{R}$$\n",
    "\n",
    "Standard deviation $\\sigma(X)$:\n",
    "$$\\sigma(X) = \\sqrt{\\text{Var}(X)}$$  \n",
    "\n",
    "Let $x \\in \\mathbb{R}^N$ a sample of size $N$ from random variable $X$.  An estimate of the variance of $X$ is:\n",
    "$$\\text{Var}(x) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2$$\n",
    "\n",
    "But this estimate is a biased estimate. Bessel's correction tries to correct the bias by dividing by $N-1$ instead of $N$:\n",
    "\n",
    "$$\\text{Var}(x) = \\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\bar{x})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.960040148361013\n",
      "1.960040148361013\n",
      "1.4000143386269346\n",
      "1.4000143386269346\n",
      "1.9744522082754326\n",
      "1.974452208275432\n"
     ]
    }
   ],
   "source": [
    "def variance(x, bias=True):\n",
    "    N = len(x)\n",
    "    div = N if bias else N - 1\n",
    "    mu = np.mean(x)\n",
    "    return np.sum((x - mu)**2) / div\n",
    "\n",
    "def std(x, bias=True):\n",
    "    return np.sqrt(variance(x, bias))\n",
    "\n",
    "x = np.random.randn(137) * 1.5 + 3.1\n",
    "print(variance(x))\n",
    "print(np.var(x))\n",
    "print(std(x))\n",
    "print(np.std(x))\n",
    "\n",
    "print(np.cov(x.reshape(1, -1)))\n",
    "print(variance(x, bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance\n",
    "\n",
    "The Covariance is a mesure of the joint variability of 2 random variables.  \n",
    "A positive value means there is a positive linear relationship ($X$ have great values when $Y$ have great values and $X$ have low values when $Y$ have low values).  \n",
    "A negative value means there is a negative linear relationship ($X$ have great values when $Y$ have low values and $X$ have low values when $Y$ have great values).  \n",
    "\n",
    "Covariance between 2 random variables $X$ and $Y$.\n",
    "$$\\text{cov}(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]$$\n",
    "$$\\text{cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X] \\mathbb{E}[Y]$$\n",
    "\n",
    "\n",
    "## Properties\n",
    "\n",
    "$$\\text{cov(X,X)} = \\text{Var(X)}$$\n",
    "$$\\text{cov(X,Y)} = \\text{cov(Y,X)}$$\n",
    "\n",
    "## Estimate\n",
    "\n",
    "Let $x$ and $y \\in \\mathbb{R}^N$ samples from respectives random variables $X$ and $Y$. An estimate of the covariance between $X$ and $Y$ is:\n",
    "\n",
    "$$\\text{cov}(x,y) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "As for the variance, we can correct the bias:\n",
    "$$\\text{cov}(x,y) = \\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "## Covariance Matrix\n",
    "\n",
    "Let $X = (X_1, \\text{...}, X_n)$ a random vector, where each entry $X_i$ is a random variable.  \n",
    "We define the covariance matrix $\\Sigma \\in \\mathbb{R}^{n*n}$ suchat that the entry $(i,j)$ is the covariance between $X_i$ and $X_j$:\n",
    "$$\\Sigma_{ij} = \\text{cov}(X_i, X_j)$$\n",
    "$$\\Sigma_{ii} = \\text{Var}(X_i)$$\n",
    "$$\\Sigma_{ij} = \\Sigma_{ji}$$\n",
    "\n",
    "\n",
    "It is also called the auto-covariance matrix or the variance-covariance matrix.  \n",
    "It generalizes the notion of variance to multiple dimensions.  \n",
    "\n",
    "Let $X \\in \\mathbb{R}^{n*p}$, where each a row is a sample of size $p$ of the random variable $X_i$.  \n",
    "We can compute an estimate of the covariance matrix $\\Sigma \\in \\mathbb{R}^{N*N}$:\n",
    "$$\\Sigma_{ij} = \\text{cov}(x_i, x_j) = \\frac{1}{p} \\sum_{k=1}^p (x_{ik} - \\bar{x}_i)(x_{jk} - \\bar{x}_j)$$\n",
    "\n",
    "When the matrix $X$ is centered (each row has mean 0), it simplifies to:\n",
    "$$\\Sigma = \\frac{1}{p} \\sum_{k=1}^p  x_{:,k} x_{:,k}^T = \\frac{1}{p} X X^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027510876759691025\n",
      "0.0027510876759690977\n",
      "9.207890622788475e-15\n",
      "9.487829036289386e-15\n",
      "3.933925374527707e-15\n"
     ]
    }
   ],
   "source": [
    "def covar(x, y, bias=True):\n",
    "    N = len(x)\n",
    "    div = N if bias else N - 1\n",
    "    mux = np.mean(x)\n",
    "    muy = np.mean(y)\n",
    "    return np.sum((x - mux) * (y - muy)) / div\n",
    "\n",
    "def covar_mat(X, bias=True):\n",
    "    n = len(X)\n",
    "    C = np.empty((n,n))\n",
    "    for i in range(n):\n",
    "        C[i,i] = variance(X[i], bias=bias)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            C[i,j] = covar(X[i], X[j], bias=bias)\n",
    "            C[j,i] = C[i,j]\n",
    "    return C\n",
    "\n",
    "def covar_mat2(X, bias=True):\n",
    "    p = X.shape[1]\n",
    "    div = p if bias else p - 1\n",
    "    X -= np.mean(X, axis=1, keepdims=True)\n",
    "    return (X @ X.T) / div\n",
    "\n",
    "x = np.random.randn(137) * 1.1 - 1.7\n",
    "y = np.random.randn(137) * 0.3 + 4.1\n",
    "\n",
    "print(covar(x, y))\n",
    "print(np.cov(np.vstack((x,y)), bias=True)[0,1])\n",
    "\n",
    "X = np.random.randn(108, 37) * 1.45 - 0.67\n",
    "C1 = np.cov(X, bias=True)\n",
    "C2 = covar_mat(X, bias=True)\n",
    "print(metrics.tdist(C1, C2))\n",
    "C1 = np.cov(X, bias=False)\n",
    "C2 = covar_mat(X, bias=False)\n",
    "print(metrics.tdist(C1, C2))\n",
    "\n",
    "C1 = np.cov(X, bias=True)\n",
    "C2 = covar_mat2(X, bias=True)\n",
    "print(metrics.tdist(C1, C2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Correlation is a mesure to how close two variables are to having a linear relationship with each other.  \n",
    "The correlation is often mesured by a correlation coefficient. They exist different types of correlation coefficients.  \n",
    "\n",
    "Two variables are said uncorellated when their correlation coefficient is $0$. It means there is no increasing or decreasing trends between the 2 variables.  \n",
    "\n",
    "## Correlation and dependance\n",
    "\n",
    "The correlation can be seen as a more specific kind of dependance. Two variables can be uncorrelated (no sign of specific trends between them), and yet be dependant.  \n",
    "$X$ and $Y$ correlated implies that they are dependants (but the opposite direction is false).  \n",
    "Similarlyy, $X$ and $Y$ independant implies that they are uncorrelated (but the opposite direction is false). \n",
    "\n",
    "## Pearson correlation coefficient\n",
    "\n",
    "It is a measure of the linear correlation between 2 variables $X$ and $Y$, ranging from $-1$ to $1$, with $+1$ a total positive linear correlation, $-1$ a total negative linear correlation, and $0$ no linear correlation.  \n",
    "\n",
    "![correlation_examples](https://upload.wikimedia.org/wikipedia/commons/0/02/Correlation_examples.png)\n",
    "\n",
    "$$\\rho(X,Y) = \\frac{\\text{cov}(X,Y)}{\\sigma(X)\\sigma(Y)}$$\n",
    "\n",
    "## Estimate\n",
    "\n",
    "Let $x$ and $y \\in \\mathbb{R}^N$ samples from respectives random variables $X$ and $Y$. An estimate of the pearson correlation coefficient between $X$ and $Y$ is:\n",
    "\n",
    "$$\\rho(x,y) =\\frac{\\text{cov}(x,y)}{\\sigma(x)\\sigma(y)} = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^N (x_i - \\bar{x})} \\sqrt{\\sum_{i=1}^N (y_i - \\bar{y})}}$$\n",
    "\n",
    "## Correlation Matrix\n",
    "\n",
    "The idea is similar to the covariance matrix. We present the correlation matrix for the pearson correlation coefficient.  \n",
    "Let $X = (X_1, \\text{...}, X_n)$ a random vector, where each entry $X_i$ is a random variable.  \n",
    "We define the correlation matrix $\\Sigma \\in \\mathbb{R}^{n*n}$ suchat that the entry $(i,j)$ is the correlation between $X_i$ and $X_j$:\n",
    "$$\\Sigma_{ij} = \\text{cov}(X_i, X_j)$$\n",
    "$$\\Sigma_{ii} = 1$$\n",
    "$$\\Sigma_{ij} = \\Sigma_{ji}$$  \n",
    "\n",
    "Let $X \\in \\mathbb{R}^{n*p}$, where each a row is a sample of size $p$ of the random variable $X_i$.  \n",
    "We can compute an estimate of the correlation matrix $\\Sigma \\in \\mathbb{R}^{N*N}$:\n",
    "$$\\Sigma_{ij} = \\rho(x_i, x_j)$$\n",
    "\n",
    "When each rows of $X$ as mean $0$ and starndard deviation $1$, it simplifies to:\n",
    "$$\\Sigma = \\frac{1}{p} \\sum_{k=1}^p  x_{:,k} x_{:,k}^T = \\frac{1}{p} X X^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05647196527337517\n",
      "0.0564719652733752\n",
      "6.849675967350832e-16\n"
     ]
    }
   ],
   "source": [
    "def corr(x, y):\n",
    "    sx = std(x)\n",
    "    sy = std(y)\n",
    "    return covar(x,y) / (sx * sy)\n",
    "\n",
    "def corr_mat(X):\n",
    "    p = X.shape[1]\n",
    "    X -= np.mean(X, axis=1, keepdims=True)\n",
    "    X /= np.std(X, axis=1, keepdims=True)\n",
    "    return (X @ X.T) / p\n",
    "    \n",
    "\n",
    "x = np.random.randn(137) * 1.1 - 1.7\n",
    "y = np.random.randn(137) * 0.3 + 4.1\n",
    "\n",
    "print(corr(x, y))\n",
    "print(np.corrcoef(np.vstack((x,y)))[0,1])\n",
    "\n",
    "X = np.random.randn(4, 37) * 1.45 - 0.67\n",
    "\n",
    "C1 = np.corrcoef(X)\n",
    "C2 = corr_mat(X)\n",
    "print(metrics.tdist(C1, C2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
