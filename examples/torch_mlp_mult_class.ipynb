{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 553.462890625, Accuracy = 0.9095337390899658\n",
      "Epoch 2: Loss = 315.73345947265625, Accuracy = 0.9464161396026611\n",
      "Epoch 3: Loss = 235.0081024169922, Accuracy = 0.9589422345161438\n",
      "Epoch 4: Loss = 239.98345947265625, Accuracy = 0.9547668695449829\n",
      "Epoch 5: Loss = 163.33432006835938, Accuracy = 0.9735560417175293\n",
      "Epoch 6: Loss = 144.26361083984375, Accuracy = 0.9812108278274536\n",
      "Epoch 7: Loss = 143.83868408203125, Accuracy = 0.9805149435997009\n",
      "Epoch 8: Loss = 126.81071472167969, Accuracy = 0.9819067716598511\n",
      "Epoch 9: Loss = 137.13677978515625, Accuracy = 0.9749478101730347\n",
      "Epoch 10: Loss = 103.44094848632812, Accuracy = 0.9839944243431091\n",
      "Epoch 11: Loss = 81.99950408935547, Accuracy = 0.9930410385131836\n",
      "Epoch 12: Loss = 79.69145202636719, Accuracy = 0.9909533858299255\n",
      "Epoch 13: Loss = 72.37704467773438, Accuracy = 0.9916492700576782\n",
      "Epoch 14: Loss = 65.76701354980469, Accuracy = 0.9937369227409363\n",
      "Epoch 15: Loss = 73.16390991210938, Accuracy = 0.9916492700576782\n",
      "Epoch 16: Loss = 59.17225646972656, Accuracy = 0.9930410385131836\n",
      "Epoch 17: Loss = 57.69432067871094, Accuracy = 0.9951287508010864\n",
      "Epoch 18: Loss = 51.197052001953125, Accuracy = 0.9951287508010864\n",
      "Epoch 19: Loss = 51.807926177978516, Accuracy = 0.9951287508010864\n",
      "Epoch 20: Loss = 47.56684875488281, Accuracy = 0.9965205192565918\n",
      "Epoch 21: Loss = 50.830833435058594, Accuracy = 0.9944328665733337\n",
      "Epoch 22: Loss = 43.504512786865234, Accuracy = 0.9979122877120972\n",
      "Epoch 23: Loss = 38.78106689453125, Accuracy = 0.9972164034843445\n",
      "Epoch 24: Loss = 36.062416076660156, Accuracy = 0.9979122877120972\n",
      "Epoch 25: Loss = 38.5087890625, Accuracy = 0.9965205192565918\n",
      "Epoch 26: Loss = 34.5151481628418, Accuracy = 0.9986082315444946\n",
      "Epoch 27: Loss = 34.50323486328125, Accuracy = 0.9986082315444946\n",
      "Epoch 28: Loss = 38.24714660644531, Accuracy = 0.9979122877120972\n",
      "Epoch 29: Loss = 28.956317901611328, Accuracy = 0.9986082315444946\n",
      "Epoch 30: Loss = 35.71073532104492, Accuracy = 0.9958246350288391\n",
      "Epoch 31: Loss = 28.082992553710938, Accuracy = 0.9986082315444946\n",
      "Epoch 32: Loss = 34.82229232788086, Accuracy = 0.9979122877120972\n",
      "Epoch 33: Loss = 26.265125274658203, Accuracy = 0.9986082315444946\n",
      "Epoch 34: Loss = 27.247398376464844, Accuracy = 0.9986082315444946\n",
      "Epoch 35: Loss = 23.341407775878906, Accuracy = 0.9986082315444946\n",
      "Epoch 36: Loss = 22.07344627380371, Accuracy = 0.9993041157722473\n",
      "Epoch 37: Loss = 23.1534423828125, Accuracy = 0.9986082315444946\n",
      "Epoch 38: Loss = 20.108299255371094, Accuracy = 0.9993041157722473\n",
      "Epoch 39: Loss = 20.71339225769043, Accuracy = 0.9986082315444946\n",
      "Epoch 40: Loss = 22.04305648803711, Accuracy = 0.9993041157722473\n",
      "Epoch 41: Loss = 20.61973762512207, Accuracy = 1.0\n",
      "Epoch 42: Loss = 18.62457275390625, Accuracy = 0.9993041157722473\n",
      "Epoch 43: Loss = 19.439353942871094, Accuracy = 0.9993041157722473\n",
      "Epoch 44: Loss = 16.714824676513672, Accuracy = 1.0\n",
      "Epoch 45: Loss = 16.16355323791504, Accuracy = 1.0\n",
      "Epoch 46: Loss = 15.965852737426758, Accuracy = 1.0\n",
      "Epoch 47: Loss = 15.259366989135742, Accuracy = 1.0\n",
      "Epoch 48: Loss = 15.353182792663574, Accuracy = 1.0\n",
      "Epoch 49: Loss = 14.537683486938477, Accuracy = 1.0\n",
      "Epoch 50: Loss = 14.173906326293945, Accuracy = 1.0\n",
      "Test Accuracy = 0.980555534362793\n",
      "proba: [[8.4893895e-07 5.6989200e-05 1.2896051e-10 4.1245431e-07 2.4909918e-05\n",
      "  1.7555883e-04 1.0738068e-09 3.1210762e-02 2.9640632e-06 9.6852732e-01]]\n",
      "true class: tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "\n",
    "### Load dataset - Preprocessing\n",
    "X, y = load_digits().data, load_digits().target\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=15)\n",
    "\n",
    "\n",
    "### Build network\n",
    "IN_SIZE = 64\n",
    "HIDDEN_SIZE = 50\n",
    "OUT_SIZE = 10\n",
    "LR=0.0005\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(IN_SIZE , HIDDEN_SIZE)\n",
    "        self.l2 = torch.nn.Linear(HIDDEN_SIZE, OUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))\n",
    "        y_logits = self.l2(x)\n",
    "        return y_logits\n",
    "\n",
    "net = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "opti = torch.optim.SGD(net.parameters(), lr=LR)\n",
    "\n",
    "### Training\n",
    "NEPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for epoch in range(NEPOCHS):\n",
    "\n",
    "    p = np.random.permutation(len(X_train))\n",
    "    X_train, y_train = X_train[p], y_train[p]\n",
    "    for ki in range(0, len(X_train), BATCH_SIZE):\n",
    "        X_batch = torch.from_numpy(X_train[ki:ki+BATCH_SIZE])\n",
    "        y_batch = torch.from_numpy(y_train[ki:ki+BATCH_SIZE])\n",
    "    \n",
    "        net.zero_grad()\n",
    "        y_logits = net(X_batch)\n",
    "        loss = criterion(y_logits, y_batch)\n",
    "        loss.backward()\n",
    "        opti.step()\n",
    "        \n",
    "    X = torch.from_numpy(X_train)\n",
    "    y = torch.from_numpy(y_train)\n",
    "    y_logits = net(X)\n",
    "    loss = criterion(y_logits, y)\n",
    "    preds = torch.argmax(y_logits, dim=1)\n",
    "    acc = y.eq(preds).sum().float() / len(X)\n",
    "    print('Epoch {}: Loss = {}, Accuracy = {}'.format(epoch+1, \n",
    "                                                      loss.data,\n",
    "                                                     acc))\n",
    "    \n",
    "    \n",
    "### Evaluate\n",
    "X = torch.from_numpy(X_test)\n",
    "y = torch.from_numpy(y_test)\n",
    "preds = torch.argmax(net(X), dim=1)\n",
    "acc = y.eq(preds).sum().float() / len(X)\n",
    "print('Test Accuracy = {}'.format(acc))\n",
    "\n",
    "X0 = X[0:1]\n",
    "y0 = y[0]\n",
    "probs = torch.softmax(net(X0), dim=1)\n",
    "print('proba:', probs.data.numpy())\n",
    "print('true class:', y0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
