{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 590.6029663085938\n",
      "Epoch 11: Loss = 80.93412780761719\n",
      "Epoch 21: Loss = 74.48310089111328\n",
      "Epoch 31: Loss = 69.8826675415039\n",
      "Epoch 41: Loss = 67.30660247802734\n",
      "Epoch 51: Loss = 66.84329986572266\n",
      "Epoch 61: Loss = 66.06513977050781\n",
      "Epoch 71: Loss = 67.98539733886719\n",
      "Epoch 81: Loss = 64.66675567626953\n",
      "Epoch 91: Loss = 64.11405181884766\n",
      "Epoch 101: Loss = 64.46937561035156\n",
      "Epoch 111: Loss = 63.321136474609375\n",
      "Epoch 121: Loss = 63.27306365966797\n",
      "Epoch 131: Loss = 62.424015045166016\n",
      "Epoch 141: Loss = 62.585784912109375\n",
      "Epoch 151: Loss = 62.47132873535156\n",
      "Epoch 161: Loss = 62.03402328491211\n",
      "Epoch 171: Loss = 61.375343322753906\n",
      "Epoch 181: Loss = 62.112205505371094\n",
      "Epoch 191: Loss = 59.46728515625\n",
      "Epoch 201: Loss = 59.07181930541992\n",
      "Epoch 211: Loss = 58.49174880981445\n",
      "Epoch 221: Loss = 60.270145416259766\n",
      "Epoch 231: Loss = 57.60791015625\n",
      "Epoch 241: Loss = 59.71610641479492\n",
      "Epoch 251: Loss = 57.4201545715332\n",
      "Epoch 261: Loss = 56.7076416015625\n",
      "Epoch 271: Loss = 54.69457244873047\n",
      "Epoch 281: Loss = 56.76450729370117\n",
      "Epoch 291: Loss = 54.944156646728516\n",
      "Epoch 301: Loss = 52.89192581176758\n",
      "Epoch 311: Loss = 64.11476135253906\n",
      "Epoch 321: Loss = 52.595611572265625\n",
      "Epoch 331: Loss = 55.663726806640625\n",
      "Epoch 341: Loss = 57.488365173339844\n",
      "Epoch 351: Loss = 49.68009948730469\n",
      "Epoch 361: Loss = 53.826663970947266\n",
      "Epoch 371: Loss = 48.817684173583984\n",
      "Epoch 381: Loss = 48.32205581665039\n",
      "Epoch 391: Loss = 48.86277389526367\n",
      "Epoch 401: Loss = 64.77136993408203\n",
      "Epoch 411: Loss = 52.90560531616211\n",
      "Epoch 421: Loss = 57.366886138916016\n",
      "Epoch 431: Loss = 46.26887512207031\n",
      "Epoch 441: Loss = 47.104949951171875\n",
      "Epoch 451: Loss = 54.670536041259766\n",
      "Epoch 461: Loss = 44.3168830871582\n",
      "Epoch 471: Loss = 64.79640197753906\n",
      "Epoch 481: Loss = 43.980411529541016\n",
      "Epoch 491: Loss = 46.66435623168945\n",
      "Test Loss: 36.134262\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "\n",
    "### Load dataset - Preprocessing\n",
    "X, y = load_boston().data, load_boston().target\n",
    "X = X.astype(np.float32)\n",
    "y = y.reshape(-1, 1).astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=15)\n",
    "# standardize data\n",
    "#Xs = np.std(X_train, axis=0, keepdims=True)\n",
    "#X_train /= Xs\n",
    "#X_test /= Xs\n",
    "\n",
    "\n",
    "### Build network\n",
    "IN_SIZE = 13\n",
    "HIDDEN_SIZE = 200\n",
    "OUT_SIZE = 1\n",
    "LR=1e-5\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(IN_SIZE , HIDDEN_SIZE)\n",
    "        self.l2 = torch.nn.Linear(HIDDEN_SIZE, OUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))\n",
    "        y_logits = self.l2(x)\n",
    "        return y_logits\n",
    "\n",
    "net = Net()\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "opti = torch.optim.SGD(net.parameters(), lr=LR)\n",
    "\n",
    "### Training\n",
    "NEPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for epoch in range(NEPOCHS):\n",
    "\n",
    "    p = np.random.permutation(len(X_train))\n",
    "    X_train, y_train = X_train[p], y_train[p]\n",
    "    for ki in range(0, len(X_train), BATCH_SIZE):\n",
    "        X_batch = torch.from_numpy(X_train[ki:ki+BATCH_SIZE])\n",
    "        y_batch = torch.from_numpy(y_train[ki:ki+BATCH_SIZE])\n",
    "    \n",
    "        net.zero_grad()\n",
    "        y_logits = net(X_batch)\n",
    "        loss = criterion(y_logits, y_batch)\n",
    "        loss.backward()\n",
    "        opti.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        X = torch.from_numpy(X_train)\n",
    "        y = torch.from_numpy(y_train)\n",
    "        y_logits = net(X)\n",
    "        loss = criterion(y_logits, y)\n",
    "        print('Epoch {}: Loss = {}'.format(epoch+1, loss.data))\n",
    "    \n",
    "    \n",
    "### Evaluate\n",
    "X = torch.from_numpy(X_test)\n",
    "y = torch.from_numpy(y_test)\n",
    "y_logits = net(X)\n",
    "loss = criterion(y_logits, y)\n",
    "print('Test Loss:', loss.data.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
