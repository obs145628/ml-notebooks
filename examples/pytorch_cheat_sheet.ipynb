{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn #neural network modules\n",
    "import torch.nn.functional as F #layers, actions, other functions\n",
    "from torch import optim # Gradient (SGD,Adam,...) and newton\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader #datasets\n",
    "\n",
    "from torchvision import datasets #famous image datasets\n",
    "from torchvision import models #famous pretrained conv models\n",
    "from torchvision import transforms #image transformations\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.randn(2, 3)\n",
    "\n",
    "x.to(device, dtype=torch.float) #move tensor to cpu/gpu\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 6), nn.ReLU())\n",
    "net.to(device) #copy all params / buffers of module to cpu/gpu\n",
    "\n",
    "x.cuda() #new tensor in GPU\n",
    "x.cpu() #new tensor in CPU\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from N(0, 1)\n",
    "x = torch.randn(2,3, dtype=torch.float, device=device, requires_grad=True)\n",
    "\n",
    "#with all 1 or 0\n",
    "y = torch.zeros(2,4, dtype=torch.float, device=device, requires_grad=True)\n",
    "z = torch.ones(2,5, dtype=torch.float, device=device, requires_grad=True)\n",
    "\n",
    "x2 = x.clone() #create a clone of x\n",
    "\n",
    "#from nested list\n",
    "a = torch.tensor([[1.,2.,3.]], device=device, requires_grad=True)\n",
    "\n",
    "torch.cat((x,y,z), dim=1) #concatenate into (2, 12)\n",
    "a = torch.cat((x, a), dim=0) #concatenate into (3, 3)\n",
    "\n",
    "torch.randint(0, 4, (3, 5)) #tensor (3,5) from 0 included to 4 excluded\n",
    "\n",
    "nx = np.random.randn(4, 6)\n",
    "x = torch.from_numpy(nx) #same tensor data than numpy: tensor (4, 6)\n",
    "x.numpy() #same tensor data than torch: numpy tensor (4,6)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 8, 6)\n",
    "x.size() #tuple (4, 8, 6)\n",
    "x.shape #(tuple 4, 8, 6)\n",
    "\n",
    "x.view(4, 8, 3, 2) #same tensor (4, 8, 3, 2)\n",
    "x.view(4, -1) #same tensor (r, 48)\n",
    "\n",
    "x.permute(0, 2, 1) #tranpose dims: same tensor (4, 6, 8)\n",
    "\n",
    "x.unsqueeze(1) #add dim of size one: same tensor (4, 1, 8, 6)\n",
    "\n",
    "x = torch.randn(3, 1, 5, 1, 7)\n",
    "x.squeeze() #remove all dims of size one: same tensor (3, 5, 7)\n",
    "x.squeeze(1) #remove dim of size one: same tensor (3, 5, 1, 7)\n",
    "\n",
    "x = torch.randn(1, 1, 1)\n",
    "x.item() #get python value of tensor of full length 1\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 7)\n",
    "y = torch.randn(4, 7)\n",
    "\n",
    "#element-wise opeartions\n",
    "x + y\n",
    "x - y\n",
    "x * y\n",
    "x / y\n",
    "x % y\n",
    "\n",
    "x = torch.randn(4, 6)\n",
    "y = torch.randn(6, 7)\n",
    "x @ y #matrix-matrix, matrix-vec, or vec-vec dot product\n",
    "x.t() #matrix transpose\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 7, requires_grad=True)\n",
    "y = torch.randn(4, 7, requires_grad=True)\n",
    "a = torch.randn(4, 7)\n",
    "E = torch.sum(a+x*y)\n",
    "\n",
    "E.backward() #compute all gradients (add to previous grad)\n",
    "x.grad #dE/dx\n",
    "y.grad #dE/dy\n",
    "\n",
    "x.grad.zero_() #reset gradient\n",
    "\n",
    "x.requires_grad #True\n",
    "(y**2).requires_grad #True\n",
    "a.requires_grad #False\n",
    "\n",
    "with torch.no_grad():\n",
    "    # no tracking computation history\n",
    "    (y**2).requires_grad #False\n",
    "    \n",
    "#start/stop tracking gradient (inplace)\n",
    "a.requires_grad_(True)\n",
    "a.requires_grad_(False)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 6)\n",
    "F.relu(x, inplace=False)\n",
    "F.leaky_relu(x, 0.2, inplace=False)\n",
    "torch.sigmoid(x)\n",
    "torch.tanh(x)\n",
    "F.logsigmoid(x)\n",
    "F.log_softmax(x, dim=1)\n",
    "F.softmax(x, dim=1)\n",
    "vals, idxs = torch.max(x, dim=1)\n",
    "torch.argmax(x, dim=1)\n",
    "torch.sum(x, dim=1)\n",
    "torch.mean(x, dim=1)\n",
    "\n",
    "F.dropout(x, p=0.5, training=True, inplace=False) #dropout operation\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net modules (operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ReLU(inplace=False)\n",
    "nn.LeakyReLU(inplace=False)\n",
    "nn.Dropout(p=0.5, inplace=False)\n",
    "nn.LogSoftmax(dim=1)\n",
    "nn.Softmax(dim=1)\n",
    "nn.Sigmoid()\n",
    "\n",
    "#batch normalization of a 4d tensors with 16 channels (N,16,w,h)\n",
    "nn.BatchNorm2d(num_features=16)\n",
    "\n",
    "nn.Sequential(nn.Sigmoid(), nn.ReLU()) #sequentil list of operations\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully connected Layer\n",
    "\n",
    "fc = nn.Linear(in_features=5, out_features=3, bias=True)\n",
    "x = torch.randn(32, 5)\n",
    "y = fc(x) #new tensor (32, 3)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding layer\n",
    "\n",
    "VOC_SIZE = 4\n",
    "VEC_LEN = 7\n",
    "embed = nn.Embedding(num_embeddings=VOC_SIZE, embedding_dim=VEC_LEN)\n",
    "\n",
    "x = torch.randint(0, VOC_SIZE, (32,))\n",
    "y = embed(x) #new tensor (32,7)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2D layer\n",
    "\n",
    "conv = nn.Conv2d(3, 64, kernel_size=(5,5), stride=(2,2), padding=(0,0),\n",
    "                bias=True)\n",
    "#kenel_size, stride, padding can take 1 number as value\n",
    "\n",
    "# compute ouput size\n",
    "def conv2d_size(size, kernel_size, stride = 1, pad = 0):\n",
    "    return (size - kernel_size + 2 * pad) // stride + 1\n",
    "\n",
    "x = torch.randn(32, 3, 120, 120)\n",
    "y = conv(x) #new tensor (32, 64, 58, 58)\n",
    "conv2d_size(120, 5, stride=2, pad=0) #58\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling layer\n",
    "#out_w = floor(in_w / kernel_w)\n",
    "#out_h = floor(in_h / kernel_h)\n",
    "\n",
    "max_pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "#kernel_size can take 1 number as value\n",
    "\n",
    "x = torch.randn(32, 3, 120, 120)\n",
    "y = max_pool(x) #new tensor (32, 3, 60, 60)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv tranpose 2D layer\n",
    "\n",
    "deconv = nn.ConvTranspose2d(16, 8, kernel_size=(5,5), stride=(2,2),\n",
    "                           padding=(0,0), bias=True)\n",
    "#kenel_size, stride, padding can take 1 number as value\n",
    "\n",
    "x = torch.randn(32, 16, 64, 64)\n",
    "y = deconv(x) #new tensor (32, 8, 131, 131)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net(120, 50, 4)\n",
    "\n",
    "x = torch.randn(32, 120)\n",
    "y = net(x) #new tensor (32, 4)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(120, 50, 4)\n",
    "\n",
    "y = net(x) #compute output value of module\n",
    "\n",
    "net.parameters() #weights of the whole module (and its components)\n",
    "\n",
    "net.to(device) #send all params and buffers of net to cpu/gpu\n",
    "\n",
    "net.zero_grad() #reset the gradient of all parameters\n",
    "\n",
    "net.eval() #set module (and its components) to evaluation mode\n",
    "net.train() #set module (and its components) to evaluation mode\n",
    "\n",
    "#get / state state dict (serialization)\n",
    "sd_net = net.state_dict()\n",
    "net.load_state_dict(sd_net)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load / Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model\n",
    "model = Net(15, 7, 2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "epoch = 4\n",
    "loss = [0.4, 0.2, 0.3, 0.1]\n",
    "\n",
    "#train model...\n",
    "\n",
    "#Save model\n",
    "torch.save({\n",
    "    'model_sd': model.state_dict(),\n",
    "    'optimizer_sd': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': loss\n",
    "}, '/tmp/model.pth')\n",
    "\n",
    "#Load model\n",
    "model = Net(15, 7, 2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "checkpoint = torch.load('/tmp/model.pth')\n",
    "model.load_state_dict(checkpoint['model_sd'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_sd'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean squared error\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "#reduction=sum takes the sum, reduction=mean divides by total items\n",
    "\n",
    "pred = torch.randn(32, 7)\n",
    "target = torch.randn(32, 7)\n",
    "loss = criterion(pred, target) #sum((pred-target)**2) / (32*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative log-likelihood\n",
    "#classification with K classes\n",
    "\n",
    "criterion = torch.nn.NLLLoss(reduction='mean')\n",
    "#reduction=sum takes the sum, reduction=mean divides by N\n",
    "\n",
    "# pred matrix (N, K). \n",
    "# Each line contains the log-probabilities for the k classes\n",
    "x = torch.randn(32, 10)\n",
    "pred = F.log_softmax(x, dim=1)\n",
    "\n",
    "# target vector (N) dtype=long\n",
    "# Each item contains the true class (0->K-1)\n",
    "target = torch.randint(0, 10, (32,))\n",
    "\n",
    "loss = criterion(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastig gradient descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#RMSProp\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01, momentum=0.9,\n",
    "                          alpha=0.99, eps=1e-8)\n",
    "\n",
    "#Adam\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, \n",
    "                       betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "\n",
    "optimizer.step() #update weights\n",
    "\n",
    "optimizer.zero_grad() #reset gradient of all parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2873,  1.4085, -0.4436,  0.3722,  1.2029, -1.2058, -0.3320],\n",
       "        dtype=torch.float64), tensor([-0.3838]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx])\n",
    "        y = torch.tensor(self.y[idx]).view(1)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "#dataset of 135 observations with 7 features + one real target\n",
    "X = np.random.randn(135, 7)\n",
    "y = np.random.randn(135)\n",
    "\n",
    "train_ds = MyDataset(X, y)\n",
    "len(train_ds) #135\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=8,\n",
    "                     shuffle=True, num_workers=4)\n",
    "\n",
    "#Iterate over the dataset by batch\n",
    "for i, (X, y) in enumerate(train_dl):\n",
    "    #i current index of batch\n",
    "    #X tensor of shape (8,7)\n",
    "    #y tensor of shape (8,1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.CenterCrop(64) #crop the image at the center to size 64\n",
    "transforms.Grayscale(1) #convert image to grayscale with 1 (or 3) chanels\n",
    "transforms.RandomCrop(64) #crop the image to size 64 at random location\n",
    "transforms.RandomHorizontalFlip(0.5) #flip image with proba 0.5\n",
    "transforms.Resize(64) #resize image to size 64\n",
    "transforms.ToTensor() #convert to torch tensor\n",
    "\n",
    "#set image mean and std for n channels\n",
    "transforms.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225])\n",
    "\n",
    "#apply a user-defined transform\n",
    "transforms.Lambda(lambda x: torch.clamp(x, 0, 1))\n",
    "\n",
    "#apply a sequence of transformations\n",
    "trfs = transforms.Compose([\n",
    "    transforms.Resize((64,64)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "x = Image.fromarray(np.random.randn(3, 120, 120).astype('uint8'), 'RGB')\n",
    "y = trfs(x) #new tensor (3, 64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResize(object):\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return x.resize((self.size, self.size), Image.BICUBIC)\n",
    "\n",
    "trfs = transforms.Compose([\n",
    "    MyResize(64), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "x = Image.fromarray(np.random.randn(3, 120, 120).astype('uint8'), 'RGB')\n",
    "y = trfs(x) #new tensor (3, 64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageFolder\n",
    "# Dataset to load images and labels for K classes\n",
    "# labels are integer from 0 to K-1\n",
    "# each item is a tuple (X, y) (PIL Image, n in [0,K-1])\n",
    "\n",
    "if False:\n",
    "    train_ds = datasets.ImageFolder('./root', transform=trfs)\n",
    "\n",
    "'''\n",
    "Directory structure:\n",
    "root/dog/xxx.png\n",
    "root/dog/xxx.png\n",
    "root/dog/xxx.png\n",
    "\n",
    "root/cat/xxx.png\n",
    "root/cat/xxx.png\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CIFAR 10 dataset\n",
    "X: image of size (3, 32, 32)\n",
    "y: label between 0 and 9\n",
    "Train set: 50.000 observations\n",
    " Test set: 10.000 observations\n",
    "'''\n",
    "if False:\n",
    "    datasets.CIFAR10(root='/tmp/data', train=True,\n",
    "                     download=True, transform=None)\n",
    "    \n",
    "\n",
    "'''\n",
    "MNIST dataset\n",
    "X: image of size (1, 28, 28)\n",
    "y: label between 0 and 9\n",
    "Train set: 60.000 observations\n",
    " Test set: 10.000 observations\n",
    "'''\n",
    "if False:\n",
    "    datasets.MNIST(root='/tmp/data', train=True,\n",
    "                     download=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss (before training): 1.2406035661697388\n",
      "epoch: 10, loss = 0.7083002788679941\n",
      "epoch: 20, loss = 0.6155309609004429\n",
      "epoch: 30, loss = 0.5778408186776297\n",
      "epoch: 40, loss = 0.5664470876966204\n",
      "epoch: 50, loss = 0.5275125205516815\n",
      "loss (after training): 0.3419869542121887\n"
     ]
    }
   ],
   "source": [
    "### Parameters ###\n",
    "LR = 0.2\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 50\n",
    "\n",
    "### Prepare dataset ###\n",
    "X = np.random.randn(70, 13).astype(np.float32)\n",
    "y = np.random.randn(70, 1).astype(np.float32)\n",
    "train_ds = MyDataset(X, y)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                     shuffle=True, num_workers=4)\n",
    "\n",
    "### Build model ###\n",
    "model = Net(13, 3, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "X, y = next(iter(train_dl))\n",
    "print('loss (before training):', criterion(model(X), y).item())\n",
    "\n",
    "### Training ###\n",
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_i, (X, y) in enumerate(train_dl):\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += len(X) * loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss = {}'.format(\n",
    "            epoch, total_loss / len(train_dl.dataset)\n",
    "        ))\n",
    "        \n",
    "X, y = next(iter(train_dl))\n",
    "print('loss (after training):', criterion(model(X), y).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
