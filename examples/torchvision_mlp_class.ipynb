{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 19617.880859375, Accuracy = 0.9027166962623596\n",
      "Epoch 2: Loss = 15585.22265625, Accuracy = 0.9244499802589417\n",
      "Epoch 3: Loss = 13759.5146484375, Accuracy = 0.932533323764801\n",
      "Epoch 4: Loss = 11149.7216796875, Accuracy = 0.9461333155632019\n",
      "Epoch 5: Loss = 10233.53125, Accuracy = 0.94964998960495\n",
      "Test Accuracy = 0.9467999935150146\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "### Load dataset - Preprocessing\n",
    "DATA_PATH = '/tmp/data'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def load_mnist(path, batch_size):\n",
    "\n",
    "    if not os.path.exists(path): os.mkdir(path)\n",
    "    trans = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "    train_set = torchvision.datasets.MNIST(root=path, train=True, \n",
    "                                           transform=trans, download=True)\n",
    "    test_set = torchvision.datasets.MNIST(root=path, train=False, \n",
    "                                          transform=trans, download=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle = False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_mnist(DATA_PATH, BATCH_SIZE)\n",
    "\n",
    "\n",
    "### Build network\n",
    "IN_SIZE = 28*28\n",
    "HIDDEN_SIZE = 50\n",
    "OUT_SIZE = 10\n",
    "LR=0.001\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(IN_SIZE , HIDDEN_SIZE)\n",
    "        self.l2 = torch.nn.Linear(HIDDEN_SIZE, OUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, IN_SIZE)\n",
    "        x = torch.relu(self.l1(x))\n",
    "        y_logits = self.l2(x)\n",
    "        return y_logits\n",
    "\n",
    "net = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "opti = torch.optim.SGD(net.parameters(), lr=LR)\n",
    "\n",
    "### Training\n",
    "NEPOCHS = 5\n",
    "\n",
    "for epoch in range(NEPOCHS):\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):    \n",
    "        net.zero_grad()\n",
    "        y_logits = net(X)\n",
    "        loss = criterion(y_logits, y)\n",
    "        loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "    \n",
    "    preds = torch.empty(len(train_loader.dataset))\n",
    "    y = torch.empty(len(train_loader.dataset))\n",
    "    loss = 0\n",
    "    for batch_idx, (bX, by) in enumerate(train_loader): \n",
    "        y_logits = net(bX)\n",
    "        bloss = criterion(y_logits, by)\n",
    "        bpreds = torch.argmax(y_logits, dim=1)\n",
    "        preds[batch_idx*BATCH_SIZE:batch_idx*BATCH_SIZE+len(bX)] = bpreds\n",
    "        y[batch_idx*BATCH_SIZE:batch_idx*BATCH_SIZE+len(bX)] = by\n",
    "        loss += bloss\n",
    "        \n",
    "    acc = y.eq(preds).sum().float() / len(y)\n",
    "    print('Epoch {}: Loss = {}, Accuracy = {}'.format(epoch+1, \n",
    "                                                      loss.data,\n",
    "                                                      acc))\n",
    "    \n",
    "    \n",
    "### Evaluate\n",
    "preds = torch.empty(len(test_loader.dataset))\n",
    "y = torch.empty(len(test_loader.dataset))\n",
    "loss = 0\n",
    "for batch_idx, (bX, by) in enumerate(test_loader): \n",
    "    y_logits = net(bX)\n",
    "    bloss = criterion(y_logits, by)\n",
    "    bpreds = torch.argmax(y_logits, dim=1)\n",
    "    preds[batch_idx*BATCH_SIZE:batch_idx*BATCH_SIZE+len(bX)] = bpreds\n",
    "    y[batch_idx*BATCH_SIZE:batch_idx*BATCH_SIZE+len(bX)] = by\n",
    "    loss += bloss\n",
    "\n",
    "acc = y.eq(preds).sum().float() / len(y)\n",
    "print('Test Accuracy = {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
