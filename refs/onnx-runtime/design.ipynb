{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level design\n",
    "\n",
    "ONNX use execution provided to abstract implemens.  \n",
    "One execution provider for each runtime / accelator.  \n",
    "An execution provided doesn't have to be able to exec all ops of graph.  \n",
    "Can divide graph into subgraphs, each running in a different execution provider.\n",
    "\n",
    "\n",
    "high-level optis:\n",
    "- graph-level transformations (global)\n",
    "- simple algebric rewriting rules (local)\n",
    "\n",
    "\n",
    "1. OONX Model => Graph Repr\n",
    "2. Apply executor independant graph transformations\n",
    "3. partition graph into set of subgraphs, each assigned to one executor\n",
    "4. compile each partition\n",
    "5. ONNX runtime execution engine runs the graph\n",
    "\n",
    "\n",
    "## API: How to use a model\n",
    "\n",
    "1. Init environement (one per process), maintains thread pool and state infos\n",
    "\n",
    "2. Init session options:\n",
    "  - optimization level\n",
    "  - add more execution providers (eg CUDA)\n",
    "\n",
    "3. Create session and load onnx model file in memory.  \n",
    "    We can get info from model: input/outputs: name, type, shapes, etc\n",
    "\n",
    "4. create input tensor objects from data values\n",
    "\n",
    "5. Run model\n",
    "\n",
    "6. Get output tensor and read data values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
