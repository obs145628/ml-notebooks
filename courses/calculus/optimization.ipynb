{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../pyutils')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition\n",
    "\n",
    "Let $f: \\mathbb{R}^N \\to \\mathbb{R}$.  \n",
    "Optimization is finding $x$ that minimizes $f(x)$.  \n",
    "Maximizing $f(x)$ is the same as minimizing $-f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar functions\n",
    "\n",
    "$f: \\mathbb{R} \\to \\mathbb{R}$.\n",
    "\n",
    "$$f(x + \\epsilon) \\approx f(x) + \\epsilon f'(x)$$\n",
    "\n",
    "$$f(x - \\epsilon \\text{sign}(f'(x)) < f(x)$$\n",
    "for $\\epsilon$ small enough\n",
    "\n",
    "We can thus reduce $f(x)$ by moving $x$ in small steps with opposite sign of $f'(x)$:\n",
    "$$x \\leftarrow x - \\epsilon \\text{sign}(f'(x))$$\n",
    "This optimisation technique is called gradient descent.  \n",
    "\n",
    "When $f'(x) = 0$, we are in a critical point, there are of 3 types:\n",
    "- local minimum: $f(x)$ lower than all neighboring points\n",
    "- local maximum: $f(x)$ greater than all neighboring points\n",
    "- saddle points: neither minimum nor maximum\n",
    "\n",
    "A global mimimum / maximum is a point $x$ with the lowest / largest value of $f(x)$.  \n",
    "A local minimum is not necesseraly a global one.  \n",
    "Applying gradient descent, we find a local minimum, that may be suboptimal compared to the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_deriv(f, x):\n",
    "    tx = torch.tensor(x, dtype=torch.float32, requires_grad=True)\n",
    "    out = my_fun(tx)\n",
    "    out.backward()\n",
    "    return tx.grad.item()\n",
    "    \n",
    "\n",
    "def my_fun(x):\n",
    "    return (x-2)**2 * (x+1) - 3 + x**2/5\n",
    "\n",
    "z = np.linspace(-3, 3, 1000)\n",
    "plt.plot(z, [my_fun(x) for x in z])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-3, 3, 1000)\n",
    "plt.plot(z, [compute_deriv(my_fun, x) for x in z])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(2.5) = -0.875 => f(1.8660000000000698) = -2.252146904\n",
      "f(-1) = -2.8 => f(-1.9999999999998899) = -18.199999999997445\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(f, step, start = None, tol=1e-28, max_iters=1000):\n",
    "    \n",
    "    if start is None:\n",
    "        start = random.random()\n",
    "    \n",
    "    x = start\n",
    "    \n",
    "    for its in range(max_iters):\n",
    "        \n",
    "        dx = compute_deriv(f, x)\n",
    "        new_x = x - step * float(np.sign(dx))\n",
    "        delta = (f(new_x) - f(x))**2\n",
    "        x = new_x\n",
    "        \n",
    "        if delta**2 < tol:\n",
    "            break\n",
    "    \n",
    "    return x\n",
    "\n",
    "start = 2.5\n",
    "res = gradient_descent(my_fun, 0.001, start=start)\n",
    "print('f({}) = {} => f({}) = {}'.format(\n",
    "    start, my_fun(start), res, my_fun(res)))\n",
    "\n",
    "start = -1\n",
    "res = gradient_descent(my_fun, 0.001, start=start)\n",
    "print('f({}) = {} => f({}) = {}'.format(\n",
    "    start, my_fun(start), res, my_fun(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector functions\n",
    "\n",
    "$f: \\mathbb{R}^n \\to \\mathbb{R}$.  \n",
    "\n",
    "The gradient vector of $f(x)$ at the point $x$ is denoted $\\nabla_x f(x)$.\n",
    "$$(\\nabla_x f(x))_i = \\frac{\\partial}{\\partial x_i} f(x)$$\n",
    "\n",
    "$x$ is a critical points if $\\nabla_x f(x) = \\vec{0}$.\n",
    "\n",
    "The directional derivative in direction $u$ (unit vector) is the slope of $f$ in direction $u$ evaluated at $x$. this is:\n",
    "$$\\frac{\\partial}{\\partial \\alpha} f(x + \\alpha u) \\space (\\alpha = 0) = u^T \\nabla_x f(x)$$  \n",
    "\n",
    "We are looking for the direction $u$ that decreases $f$ the fastest:\n",
    "$$\\min_{u, u^Tu=1}u^T\\nabla_x f(x)$$\n",
    "$$ = \\min_{u, u^Tu=1} ||u||_2 ||\\nabla_x f(x)|| \\cos \\theta$$\n",
    "$$ = \\min_{u} \\cos \\theta$$\n",
    "with $\\theta$ the angle between $u$ and the gradient.  \n",
    "The solution is $u$ pointing in the opposite direction of the gradient.  \n",
    "\n",
    "Gradient descent in vector functions proposes the following update:\n",
    "$$x \\leftarrow x - \\epsilon \\nabla_x f(x)$$\n",
    "\n",
    "with $\\sigma \\in \\mathbb{R}$, $\\sigma > 0$ the learning rate, might be chosen:\n",
    "- small constant\n",
    "- line search: try several values, take the ones that reduce the most\n",
    "\n",
    "It converges to local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 54\n",
    "IN_SIZE = 8\n",
    "HIDDEN = 5\n",
    "OUT_SIZE = 1\n",
    "\n",
    "X = torch.randn(N, IN_SIZE)\n",
    "y = torch.randn(N, OUT_SIZE)\n",
    "\n",
    "def my_net(W1, W2):\n",
    "    \n",
    "    out = torch.relu(X @ W1)\n",
    "    out = out @ W2\n",
    "    \n",
    "    loss = torch.mean((out - y)**2)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 27.256473541259766\n",
      "Iteration 31, loss = 2.3146841526031494\n",
      "Iteration 61, loss = 1.4958083629608154\n",
      "Iteration 91, loss = 1.2893446683883667\n",
      "Iteration 121, loss = 1.213019847869873\n",
      "Iteration 151, loss = 1.180122971534729\n",
      "Iteration 181, loss = 1.1647608280181885\n",
      "Iteration 211, loss = 1.157124400138855\n",
      "Iteration 241, loss = 1.1530524492263794\n",
      "Iteration 271, loss = 1.1506593227386475\n",
      "Iteration 301, loss = 1.1490594148635864\n",
      "Iteration 331, loss = 1.1478304862976074\n",
      "Iteration 361, loss = 1.1467729806900024\n",
      "Iteration 391, loss = 1.1458485126495361\n",
      "Iteration 421, loss = 1.1451579332351685\n",
      "Iteration 451, loss = 1.144492506980896\n",
      "Iteration 481, loss = 1.143834114074707\n",
      "Iteration 511, loss = 1.1431735754013062\n",
      "Iteration 541, loss = 1.1425058841705322\n",
      "Iteration 571, loss = 1.1418284177780151\n",
      "Iteration 601, loss = 1.1411124467849731\n",
      "Iteration 631, loss = 1.140347957611084\n",
      "Iteration 661, loss = 1.1395683288574219\n",
      "Iteration 691, loss = 1.1387735605239868\n",
      "Iteration 721, loss = 1.1379634141921997\n",
      "Iteration 751, loss = 1.137157917022705\n",
      "Iteration 781, loss = 1.1363520622253418\n",
      "Iteration 811, loss = 1.135529637336731\n",
      "Iteration 841, loss = 1.1346901655197144\n",
      "Iteration 871, loss = 1.13387930393219\n",
      "Iteration 901, loss = 1.1330602169036865\n",
      "Iteration 931, loss = 1.1322247982025146\n",
      "Iteration 961, loss = 1.1313717365264893\n",
      "Iteration 991, loss = 1.1304999589920044\n"
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "\n",
    "def gradient_descent(lr, niters=1000):\n",
    "    \n",
    "    W1 = torch.randn(IN_SIZE, HIDDEN, requires_grad=True)\n",
    "    W2 = torch.randn(HIDDEN, OUT_SIZE, requires_grad=True)\n",
    "    \n",
    "    loss = my_net(W1, W2)\n",
    "    \n",
    "    for it in range(niters):\n",
    "        \n",
    "        loss = my_net(W1, W2)\n",
    "        loss.backward()\n",
    "        \n",
    "        W1.data.sub_(lr * W1.grad.data)\n",
    "        W2.data.sub_(lr * W2.grad.data)\n",
    "        W1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "        \n",
    "        if it % 30 == 0:\n",
    "            print('Iteration {}, loss = {}'.format(it+1,\n",
    "                 loss.item()))\n",
    "    \n",
    "    return W1, W2\n",
    "    \n",
    "\n",
    "res_w1, res_w2 = gradient_descent(lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobian and Hessian\n",
    "\n",
    "Let $f: \\mathbb{R}^m \\to \\mathbb{R}^n$.  \n",
    "The Jacobian matrix $J \\in \\mathbb{R}^{n*m}$ contains all the partial derivates of $f$ at a particual point $x$:\n",
    "$$J_{ij} = \\frac{\\partial}{\\partial x_j} f(x)_i$$  \n",
    "\n",
    "Let $f: \\mathbb{R}^n \\to \\mathbb{R}$.  \n",
    "The Hesian matrix $H \\in \\mathbb{R}^{n*n}$ contains all the second partial derivates of $f$ at a particular point $x$:\n",
    "$$H_{ij} = \\frac{\\partial^2}{\\partial x_i \\partial x_j} f(x)$$  \n",
    "\n",
    "The Hessian is the Jacobian of the gradient.  \n",
    "\n",
    "If $f$ second partial derivative is continuous in $x$, the Hessian is symmetric.\n",
    "\n",
    "The second derivative tells us is a gradient step will do as much improvement as we expected.  \n",
    "Suppose we have a quadratic scalar function:\n",
    "- $f''(x) = 0$: a gradient step will move exactly as expected by the gradient.\n",
    "- $f''(x) > 0$: a gradient step will move less than expected.\n",
    "- $f''(x) < 0$: a gradient step will move less than expected.  \n",
    "\n",
    "If $x$ is a critical point, $f'(x)=0$, the second derivates gives more information:\n",
    "- $f''(x) < 0$: $x$ is a local maximum\n",
    "- $f''(x) > 0$: $x$ is a local minimum\n",
    "- $f''(x) = 0$: may be any of the 3\n",
    "\n",
    "In higher dimensions, we can look at the Hessian eigeinvalues to know what kind of critical point $x$ is ($\\nabla_x f(x) = \\vec{0}$):\n",
    "- all eigenvalues are negative: $x$ is a local maximum\n",
    "- all eigenvalues are positive: $x$ is a local minimum\n",
    "- there is at least one positive and one negative eigenvalue: $x$ is a saddle point\n",
    "- otherwhise: may be any of the 3\n",
    "\n",
    "If the Hessian has a poor condition number, the second derivatives differ a lot from each other, and gradient descent performs poorly.  \n",
    "We could use the information on the Hessian to guide the search.  \n",
    "\n",
    "Newton's method use a second-order Taylor series expansion to make a quadratic approximation of $f$ near $x^{(0)}$:\n",
    "\n",
    "$$f(x) \\approx f(x^{(0)}) + (x - x^{(0)})^Tg + \\frac{1}{2} (x - x^{(0)})^T H (x - x^{(0)})$$\n",
    "\n",
    "with $g = \\nabla_x f(x^{(0)})$ and $H$ the Hessian of $f$ at $x^{(0)}$.\n",
    "\n",
    "Solving for a critical point, we obtain:\n",
    "$$x^* = x^{(0)} - H^{-1}g$$\n",
    "\n",
    "When $f$ is quadratic, only one update jumps to the minimum. Otherwhise, we can recursively make the update, it converges a lot faster than gradient descent.  \n",
    "But newton's method are a lot more attracted to saddle points than gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) torch.Size([8, 8])\n",
      "0.0\n",
      "3.6603196e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "def compute_grad_hessian(loss, w):\n",
    "    \n",
    "    w_grad, = autograd.grad(loss, w, create_graph=True, retain_graph=True)\n",
    "    \n",
    "    hess = []\n",
    "    for i in range(len(w_grad)):    \n",
    "        hess.append(autograd.grad(w_grad[i], w,\n",
    "                    create_graph=True, retain_graph=True)[0])\n",
    "    \n",
    "    w_hess = torch.stack(hess, dim=0)\n",
    "    \n",
    "    return w_grad, w_hess\n",
    "\n",
    "beta = torch.randn(IN_SIZE, requires_grad = True)\n",
    "\n",
    "l1_coef = 0.4\n",
    "\n",
    "pred = X @ beta\n",
    "err = (y.squeeze() - pred)\n",
    "loss = (err @ err) + l1_coef * beta @ beta\n",
    "\n",
    "beta_grad, beta_hess = compute_grad_hessian(loss, beta)\n",
    "\n",
    "\n",
    "bgrad_ref = - 2 * X.t() @ (y.squeeze() - X @ beta) + 2 * l1_coef * beta\n",
    "bhess_ref = 2 * X.t() @ X + 2 * l1_coef * torch.eye(len(beta))\n",
    "print(beta_grad.shape, beta_hess.shape)\n",
    "print(metrics.tdist(bgrad_ref.data.numpy(), beta_grad.data.numpy()))\n",
    "print(metrics.tdist(bhess_ref.data.numpy(), beta_hess.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) torch.Size([5, 5])\n",
      "tensor([ 2.2695,  5.0394, -1.0224, -0.0292, -0.1943], grad_fn=<ViewBackward>)\n",
      "tensor([[ 1.9316,  0.8081, -0.2022, -0.0647, -0.7060],\n",
      "        [ 0.8081,  3.3117, -0.5739, -0.0595, -1.0549],\n",
      "        [-0.2022, -0.5739,  0.1785,  0.0195,  0.2155],\n",
      "        [-0.0647, -0.0595,  0.0195,  0.0074,  0.0455],\n",
      "        [-0.7060, -1.0549,  0.2155,  0.0455,  1.3261]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "W1 = torch.randn(IN_SIZE, HIDDEN)\n",
    "W2 = torch.randn(HIDDEN, OUT_SIZE, requires_grad=True)\n",
    "\n",
    "def my_net(b):\n",
    "    \n",
    "    out = torch.relu(X @ W1 + b)\n",
    "    out = out @ W2\n",
    "    \n",
    "    loss = torch.mean((out - y)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "b = torch.randn(HIDDEN, requires_grad=True)\n",
    "    \n",
    "\n",
    "loss = my_net(b)\n",
    "b_grad, b_hess = compute_grad_hessian(loss, b)\n",
    "\n",
    "\n",
    "print(b_grad.shape, b_hess.shape)\n",
    "print(b_grad)\n",
    "print(b_hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 21.246177673339844\n",
      "Iteration 11, loss = 18.76519203186035\n",
      "Iteration 21, loss = 16.528507232666016\n",
      "Iteration 31, loss = 14.489789962768555\n",
      "Iteration 41, loss = 12.661669731140137\n",
      "Iteration 51, loss = 11.081941604614258\n",
      "Iteration 61, loss = 9.753718376159668\n",
      "Iteration 71, loss = 8.629889488220215\n",
      "Iteration 81, loss = 7.7066826820373535\n",
      "Iteration 91, loss = 6.889970779418945\n"
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "\n",
    "def newton_method(lr, niters=100):\n",
    "    \n",
    "    b = torch.randn(HIDDEN, requires_grad=True)\n",
    "    \n",
    "    loss = my_net(b)\n",
    "    \n",
    "    for it in range(niters):\n",
    "        \n",
    "        loss = my_net(b)\n",
    "        b_grad, b_hess = compute_grad_hessian(loss, b)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            db = torch.inverse(b_hess) @ b_grad\n",
    "            b.data.sub_(lr * db.data)\n",
    "        \n",
    "        if it % 10 == 0:\n",
    "            print('Iteration {}, loss = {}'.format(it+1,\n",
    "                 loss.item()))\n",
    "    \n",
    "    return b\n",
    "\n",
    "res_b = newton_method(lr=LR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
