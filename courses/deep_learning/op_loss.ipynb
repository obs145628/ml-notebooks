{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../pyutils')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error (MSE)\n",
    "\n",
    "The predictions of the model are denoted $\\hat{y}$, the true values are denoted $y$.  \n",
    "This is a 1D version, without average. We can reshape the input and multiply by a constant term to handle average and multi-dimensional data.\n",
    "\n",
    "# Forward pass\n",
    "\n",
    "$$l = \\sum_{i=1}^n(\\hat{y}_i - y_i)^2, \\space \\hat{y}, y \\in \\mathbb{R}^n, l \\in \\mathbb{R}$$\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial \\hat{y}} = 2 * \\frac{\\partial E}{\\partial l} * (\\hat{y} - y)$$\n",
    "$$\\frac{\\partial E}{\\partial y} = 2 * \\frac{\\partial E}{\\partial l} * (y - \\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def mse(pred, target):\n",
    "    return np.sum((pred - target)**2)\n",
    "\n",
    "def mse_dpred(pred, target, dout):\n",
    "    return 2 * dout * (pred - target)\n",
    "\n",
    "def mse_dtarget(pred, target, dout):\n",
    "    return 2 * dout * (target - pred)\n",
    "\n",
    "pred = np.random.randn(26, 4, 8).astype(np.float32)\n",
    "target = np.random.randn(26, 4, 8).astype(np.float32)\n",
    "l = mse(pred, target)\n",
    "loss = np.sum(l**2)\n",
    "dl = 2*l\n",
    "dpred = mse_dpred(pred, target, dl)\n",
    "dtarget = mse_dtarget(pred, target, dl)\n",
    "\n",
    "\n",
    "tpred = torch.from_numpy(pred).requires_grad_(True)\n",
    "ttarget = torch.from_numpy(target).requires_grad_(True)\n",
    "tl = F.mse_loss(tpred, ttarget, reduction='sum')\n",
    "tloss = torch.sum(tl**2)\n",
    "tloss.backward()\n",
    "tdpred = tpred.grad\n",
    "tdtarget = ttarget.grad\n",
    "\n",
    "print(metrics.tdist(l, tl.data.numpy()))\n",
    "print(metrics.tdist(dpred, tdpred.data.numpy()))\n",
    "print(metrics.tdist(dtarget, tdtarget.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "\n",
    "The predictions of the model are denoted $\\hat{y}$, the true values are denoted $y$.  \n",
    "This is a 1D version, without average. We can reshape the input and multiply by a constant term to handle average and multi-dimensional data.\n",
    "\n",
    "# Forward pass\n",
    "\n",
    "$$l = \\sum_{i=1}^n |\\hat{y}_i - y_i|, \\space \\hat{y}, y \\in \\mathbb{R}^n, l \\in \\mathbb{R}$$\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial \\hat{y}} = \\frac{\\partial E}{\\partial l} * \\text{sign}(\\hat{y} - y)$$\n",
    "$$\\frac{\\partial E}{\\partial y} = \\frac{\\partial E}{\\partial l} * \\text{sign}(y - \\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def mae(pred, target):\n",
    "    return np.sum(np.abs(pred - target))\n",
    "\n",
    "def mae_dpred(pred, target, dout):\n",
    "    return dout * np.sign(pred - target)\n",
    "\n",
    "def mae_dtarget(pred, target, dout):\n",
    "    return dout * np.sign(target - pred)\n",
    "\n",
    "pred = np.random.randn(26, 4, 8).astype(np.float32)\n",
    "target = np.random.randn(26, 4, 8).astype(np.float32)\n",
    "l = mae(pred, target)\n",
    "loss = np.sum(l**2)\n",
    "dl = 2*l\n",
    "dpred = mae_dpred(pred, target, dl)\n",
    "dtarget = mae_dtarget(pred, target, dl)\n",
    "\n",
    "\n",
    "tpred = torch.from_numpy(pred).requires_grad_(True)\n",
    "ttarget = torch.from_numpy(target).requires_grad_(True)\n",
    "tl = F.l1_loss(tpred, ttarget, reduction='sum')\n",
    "tloss = torch.sum(tl**2)\n",
    "tloss.backward()\n",
    "tdpred = tpred.grad\n",
    "tdtarget = ttarget.grad\n",
    "\n",
    "print(metrics.tdist(l, tl.data.numpy()))\n",
    "print(metrics.tdist(dpred, tdpred.data.numpy()))\n",
    "print(metrics.tdist(dtarget, tdtarget.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Cross Entropy (BCE)\n",
    "\n",
    "The predictions of the model are denoted $\\hat{y}$, they are the probabilities of belonging to class $1$.  \n",
    "The true values are denoted $y$, they are $1$ if belong to class $1$, or $0$.\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "\n",
    "$$l = - \\sum_{i=1}^N (y_i log(\\hat{y_i}) + (1 - y_i) log(1 - \\hat{y_i})), \\space \\hat{y}, y \\in \\mathbb{R}^N, l \\in \\mathbb{R}$$\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial \\hat{y}} = \\frac{\\partial E}{\\partial l} * \\frac{\\hat{y} - y}{\\hat{y}(1 - \\hat{y})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8146973e-06\n",
      "0.0039273673\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def bce(pred, target):\n",
    "    return - np.sum(target*np.log(pred)+(1-target) * np.log(1-pred))\n",
    "\n",
    "def bce_dpred(pred, target, dout):\n",
    "    return dout * (pred - target) / (pred * (1 - pred))\n",
    "\n",
    "pred = np.random.rand(26).astype(np.float32)\n",
    "target = np.random.randint(0, 2, size=26).astype(np.float32)\n",
    "l = bce(pred, target)\n",
    "loss = np.sum(l**2)\n",
    "dl = 2*l\n",
    "dpred = bce_dpred(pred, target, dl)\n",
    "\n",
    "\n",
    "tpred = torch.from_numpy(pred).requires_grad_(True)\n",
    "ttarget = torch.from_numpy(target)\n",
    "tl = F.binary_cross_entropy(tpred, ttarget, reduction='sum')\n",
    "tloss = torch.sum(tl**2)\n",
    "tloss.backward()\n",
    "tdpred = tpred.grad\n",
    "\n",
    "print(metrics.tdist(l, tl.data.numpy()))\n",
    "print(metrics.tdist(dpred, tdpred.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy (CE)\n",
    "\n",
    "The predictions of the model are denoted $\\hat{y}$, they are the probabilities of belonging to each of the K classes.  \n",
    "The true values are denoted $y$, a one-hot representation with $1$ for the true class.\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "\n",
    "$$l = - \\sum_{i=1}^N \\sum_{j=1}^K [y_{ij} log(\\hat{y_{ij}})], \\space \\hat{y}, y \\in \\mathbb{R}^{N*K}, l \\in \\mathbb{R}$$\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial \\hat{y}} = - \\frac{\\partial E}{\\partial l} * \\frac{y}{\\hat{y}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def target2onehot(x, nclasses):\n",
    "    oh = np.zeros((len(x), nclasses)).astype(np.float32)\n",
    "    oh[np.arange(len(x)), x] = 1\n",
    "    return oh\n",
    "\n",
    "def cross_entropy(pred, target):\n",
    "    return - np.sum(target * np.log(pred))\n",
    "\n",
    "def cross_entropy_dpred(pred, target, dout):\n",
    "    return - dout * target / pred\n",
    "\n",
    "pred = np.random.rand(26, 4).astype(np.float32)\n",
    "pred = pred / np.sum(pred, axis=1, keepdims=True)\n",
    "target = np.random.randint(0, 4, size=26).astype(np.int)\n",
    "target = target2onehot(target, 4)\n",
    "l = cross_entropy(pred, target)\n",
    "loss = np.sum(l**2)\n",
    "dl = 2*l\n",
    "dpred = cross_entropy_dpred(pred, target, dl)\n",
    "\n",
    "\n",
    "tpred = torch.from_numpy(pred).requires_grad_(True)\n",
    "ttarget = torch.from_numpy(target)\n",
    "tl =  - torch.sum(ttarget * torch.log(tpred))\n",
    "tloss = torch.sum(tl**2)\n",
    "tloss.backward()\n",
    "tdpred = tpred.grad\n",
    "\n",
    "print(metrics.tdist(l, tl.data.numpy()))\n",
    "print(metrics.tdist(dpred, tdpred.data.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
