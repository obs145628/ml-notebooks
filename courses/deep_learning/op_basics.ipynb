{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../pyutils')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "$$Z = X Y, \\space X \\in \\mathbb{R}^{m*n}, Y \\in \\mathbb{R}^{n*p}, X \\in \\mathbb{R}^{m*p}$$\n",
    "\n",
    "## Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial X} = \\frac{\\partial E}{\\partial Z} Y^T$$\n",
    "$$\\frac{\\partial E}{\\partial Y} = X^T \\frac{\\partial E}{\\partial Z}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def matmul(x, y):\n",
    "    return x @ y\n",
    "\n",
    "def matmul_dx(x, y, dout):\n",
    "    return dout @ y.T\n",
    "\n",
    "def matmul_dy(x, y, dout):\n",
    "    return x.T @ dout\n",
    "\n",
    "x = np.random.randn(4, 6).astype(np.float32)\n",
    "y = np.random.randn(6, 9).astype(np.float32)\n",
    "z = matmul(x, y)\n",
    "loss = np.sum(z**2)\n",
    "dz = 2*z\n",
    "dx = matmul_dx(x, y, dz)\n",
    "dy = matmul_dy(x, y, dz)\n",
    "\n",
    "\n",
    "tx = torch.from_numpy(x).requires_grad_(True)\n",
    "ty = torch.from_numpy(y).requires_grad_(True)\n",
    "tz = tx @ ty\n",
    "tloss = torch.sum(tz**2)\n",
    "tloss.backward()\n",
    "tdx = tx.grad\n",
    "tdy = ty.grad\n",
    "\n",
    "print(metrics.tdist(z, tz.data.numpy()))\n",
    "print(metrics.tdist(dx, tdx.data.numpy()))\n",
    "print(metrics.tdist(dy, tdy.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add bias\n",
    "\n",
    "This is an operation that takes a 3D tensor $X$ and vector $y$ and sum both of them on the second axis of $X$.  \n",
    "This is a general operation that can implement many types of add bias by reshaping the inputs correctly\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "$$Z = \\text{add_bias}(X, y) \\space X, Z \\in \\mathbb{R}^{n*m*p}, y \\in \\mathbb{R}^m$$\n",
    "\n",
    "$$Z_{ijk} = X_{ijk} + b_{j}$$\n",
    "\n",
    "## Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial X} = \\frac{\\partial E}{\\partial Z}$$\n",
    "$$\\frac{\\partial E}{\\partial y_j} = \\sum_{i=1}^n \\sum_{k=1}^p \\frac{\\partial E}{\\partial Z_{ijk}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "5.415829e-06\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def add_bias(x, y):\n",
    "    return x + y.reshape(1, -1, 1)\n",
    "\n",
    "def add_bias_dx(x, y, dout):\n",
    "    return dout\n",
    "\n",
    "def add_bias_dy(x, y, dout):\n",
    "    return np.sum(dout, axis=(0,2))\n",
    "\n",
    "x = np.random.randn(4, 6, 3).astype(np.float32)\n",
    "y = np.random.randn(6).astype(np.float32)\n",
    "z = add_bias(x, y)\n",
    "loss = np.sum(z**2)\n",
    "dz = 2*z\n",
    "dx = add_bias_dx(x, y, dz)\n",
    "dy = add_bias_dy(x, y, dz)\n",
    "\n",
    "\n",
    "tx = torch.from_numpy(x).requires_grad_(True)\n",
    "ty = torch.from_numpy(y).requires_grad_(True)\n",
    "tz = tx + ty.view(1, -1, 1)\n",
    "tloss = torch.sum(tz**2)\n",
    "tloss.backward()\n",
    "tdx = tx.grad\n",
    "tdy = ty.grad\n",
    "\n",
    "print(metrics.tdist(z, tz.data.numpy()))\n",
    "print(metrics.tdist(dx, tdx.data.numpy()))\n",
    "print(metrics.tdist(dy, tdy.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear transformation (FC layer)\n",
    "\n",
    "Perform a linear transformation with bias, with $p$ input units and $k$ output units.\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "$$Y = XW^T + b, \\space X \\in \\mathbb{R}^{N*p}, W \\in \\mathbb{R}^{k*p}, b \\in \\mathbb{R}^k, Y \\in \\mathbb{R}^{N*k}$$\n",
    "\n",
    "\n",
    "## Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial X} = \\frac{\\partial E}{\\partial Z} W$$\n",
    "$$\\frac{\\partial E}{\\partial W} = X^T \\frac{\\partial E}{\\partial Z}$$\n",
    "$$\\frac{\\partial E}{\\partial b_j} = \\sum_{i=1}^N \\frac{\\partial E}{\\partial Y_{ij}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def linear(x, w, b):\n",
    "    return x @ w.T + b\n",
    "\n",
    "def linear_dx(x, w, b, dout):\n",
    "    return dout @ w\n",
    "\n",
    "def linear_dw(x, w, b, dout):\n",
    "    return dout.T @ x\n",
    "\n",
    "def linear_db(x, w, b, dout):\n",
    "    return np.sum(dout, axis=0)\n",
    "\n",
    "x = np.random.randn(18, 14).astype(np.float32)\n",
    "w = np.random.randn(5, 14).astype(np.float32)\n",
    "b = np.random.randn(5).astype(np.float32)\n",
    "y = linear(x, w, b)\n",
    "loss = np.sum(y**2)\n",
    "dy = 2*y\n",
    "dx = linear_dx(x, w, b, dy)\n",
    "dw = linear_dw(x, w, b, dy)\n",
    "db = linear_db(x, w, b, dy)\n",
    "\n",
    "tx = torch.from_numpy(x).requires_grad_(True)\n",
    "tw = torch.from_numpy(w).requires_grad_(True)\n",
    "tb = torch.from_numpy(b).requires_grad_(True)\n",
    "ty = F.linear(tx, tw, tb)\n",
    "tloss = torch.sum(ty**2)\n",
    "tloss.backward()\n",
    "tdx = tx.grad\n",
    "tdw = tw.grad\n",
    "tdb = tb.grad\n",
    "\n",
    "print(metrics.tdist(y, ty.data.numpy()))\n",
    "print(metrics.tdist(dx, tdx.data.numpy()))\n",
    "print(metrics.tdist(dw, tdw.data.numpy()))\n",
    "print(metrics.tdist(db, tdb.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "$$y = \\sum_{i=1}^n X_i, \\space X \\in \\mathbb{R}^n, y \\in \\mathbb{R}$$\n",
    "\n",
    "## Backward pass\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial X} = \\frac{\\partial E}{\\partial y} * \\mathbb{1}_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.536743e-07\n",
      "1.6184389828183307e-05\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "def vsum(x):\n",
    "    return np.sum(x)\n",
    "\n",
    "def vsum_dx(x, dout):\n",
    "    return dout * np.ones(x.shape)\n",
    "\n",
    "x = np.random.randn(4, 6, 3).astype(np.float32)\n",
    "y = vsum(x)\n",
    "loss = np.sum(y**2)\n",
    "dy = 2*y\n",
    "dx = vsum_dx(x, dy)\n",
    "\n",
    "tx = torch.from_numpy(x).requires_grad_(True)\n",
    "ty = torch.sum(tx)\n",
    "tloss = torch.sum(ty**2)\n",
    "tloss.backward()\n",
    "tdx = tx.grad\n",
    "\n",
    "print(metrics.tdist(y, ty.data.numpy()))\n",
    "print(metrics.tdist(dx, tdx.data.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
